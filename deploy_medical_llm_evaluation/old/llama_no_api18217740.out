Many modules are hidden in this stack. Use "module --show_hidden spider SOFTWARE" if you are not able to find the required software
# packages in environment at /cluster/home/gcardenal/miniconda3/envs/vllm:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main  
_openmp_mutex             5.1                       1_gnu  
accelerate                1.1.1                    pypi_0    pypi
aiohappyeyeballs          2.4.0                    pypi_0    pypi
aiohttp                   3.10.6                   pypi_0    pypi
aiosignal                 1.3.1                    pypi_0    pypi
annotated-types           0.7.0                    pypi_0    pypi
anthropic                 0.40.0                   pypi_0    pypi
anyio                     4.6.0                    pypi_0    pypi
argon2-cffi               23.1.0                   pypi_0    pypi
argon2-cffi-bindings      21.2.0                   pypi_0    pypi
arrow                     1.3.0                    pypi_0    pypi
asttokens                 3.0.0                    pypi_0    pypi
async-lru                 2.0.4                    pypi_0    pypi
async-timeout             4.0.3                    pypi_0    pypi
attrs                     24.2.0                   pypi_0    pypi
babel                     2.16.0                   pypi_0    pypi
beautifulsoup4            4.12.3                   pypi_0    pypi
bleach                    6.2.0                    pypi_0    pypi
bzip2                     1.0.8                h5eee18b_6  
ca-certificates           2024.7.2             h06a4308_0  
certifi                   2024.8.30                pypi_0    pypi
cffi                      1.17.1                   pypi_0    pypi
charset-normalizer        3.3.2                    pypi_0    pypi
click                     8.1.7                    pypi_0    pypi
cloudpickle               3.0.0                    pypi_0    pypi
comm                      0.2.2                    pypi_0    pypi
datasets                  3.0.1                    pypi_0    pypi
debugpy                   1.8.9                    pypi_0    pypi
decorator                 5.1.1                    pypi_0    pypi
defusedxml                0.7.1                    pypi_0    pypi
dill                      0.3.8                    pypi_0    pypi
diskcache                 5.6.3                    pypi_0    pypi
distro                    1.9.0                    pypi_0    pypi
einops                    0.8.0                    pypi_0    pypi
emoji                     2.14.0                   pypi_0    pypi
exceptiongroup            1.2.2                    pypi_0    pypi
executing                 2.1.0                    pypi_0    pypi
fastapi                   0.115.0                  pypi_0    pypi
fastjsonschema            2.21.1                   pypi_0    pypi
filelock                  3.16.1                   pypi_0    pypi
fqdn                      1.5.1                    pypi_0    pypi
frozenlist                1.4.1                    pypi_0    pypi
fsspec                    2024.6.1                 pypi_0    pypi
gguf                      0.10.0                   pypi_0    pypi
h11                       0.14.0                   pypi_0    pypi
httpcore                  1.0.5                    pypi_0    pypi
httptools                 0.6.1                    pypi_0    pypi
httpx                     0.28.0                   pypi_0    pypi
huggingface-hub           0.25.1                   pypi_0    pypi
idna                      3.10                     pypi_0    pypi
importlib-metadata        8.5.0                    pypi_0    pypi
interegular               0.3.3                    pypi_0    pypi
ipykernel                 6.29.5                   pypi_0    pypi
ipython                   8.30.0                   pypi_0    pypi
ipywidgets                8.1.5                    pypi_0    pypi
isoduration               20.11.0                  pypi_0    pypi
jedi                      0.19.2                   pypi_0    pypi
jinja2                    3.1.4                    pypi_0    pypi
jiter                     0.5.0                    pypi_0    pypi
json5                     0.10.0                   pypi_0    pypi
jsonpointer               3.0.0                    pypi_0    pypi
jsonschema                4.23.0                   pypi_0    pypi
jsonschema-specifications 2023.12.1                pypi_0    pypi
jupyter                   1.1.1                    pypi_0    pypi
jupyter-client            8.6.3                    pypi_0    pypi
jupyter-console           6.6.3                    pypi_0    pypi
jupyter-core              5.7.2                    pypi_0    pypi
jupyter-events            0.10.0                   pypi_0    pypi
jupyter-lsp               2.2.5                    pypi_0    pypi
jupyter-server            2.14.2                   pypi_0    pypi
jupyter-server-terminals  0.5.3                    pypi_0    pypi
jupyterlab                4.3.2                    pypi_0    pypi
jupyterlab-pygments       0.3.0                    pypi_0    pypi
jupyterlab-server         2.27.3                   pypi_0    pypi
jupyterlab-widgets        3.0.13                   pypi_0    pypi
lark                      1.2.2                    pypi_0    pypi
ld_impl_linux-64          2.40                 h12ee557_0  
libffi                    3.4.4                h6a678d5_1  
libgcc-ng                 11.2.0               h1234567_1  
libgomp                   11.2.0               h1234567_1  
libstdcxx-ng              11.2.0               h1234567_1  
libuuid                   1.41.5               h5eee18b_0  
llvmlite                  0.43.0                   pypi_0    pypi
lm-format-enforcer        0.10.6                   pypi_0    pypi
markupsafe                2.1.5                    pypi_0    pypi
matplotlib-inline         0.1.7                    pypi_0    pypi
mistral-common            1.4.3                    pypi_0    pypi
mistune                   3.0.2                    pypi_0    pypi
mpmath                    1.3.0                    pypi_0    pypi
msgpack                   1.1.0                    pypi_0    pypi
msgspec                   0.18.6                   pypi_0    pypi
multidict                 6.1.0                    pypi_0    pypi
multiprocess              0.70.16                  pypi_0    pypi
nbclient                  0.10.1                   pypi_0    pypi
nbconvert                 7.16.4                   pypi_0    pypi
nbformat                  5.10.4                   pypi_0    pypi
ncurses                   6.4                  h6a678d5_0  
nest-asyncio              1.6.0                    pypi_0    pypi
networkx                  3.3                      pypi_0    pypi
notebook                  7.3.1                    pypi_0    pypi
notebook-shim             0.2.4                    pypi_0    pypi
numba                     0.60.0                   pypi_0    pypi
numpy                     1.26.4                   pypi_0    pypi
nvidia-cublas-cu12        12.1.3.1                 pypi_0    pypi
nvidia-cuda-cupti-cu12    12.1.105                 pypi_0    pypi
nvidia-cuda-nvrtc-cu12    12.1.105                 pypi_0    pypi
nvidia-cuda-runtime-cu12  12.1.105                 pypi_0    pypi
nvidia-cudnn-cu12         9.1.0.70                 pypi_0    pypi
nvidia-cufft-cu12         11.0.2.54                pypi_0    pypi
nvidia-curand-cu12        10.3.2.106               pypi_0    pypi
nvidia-cusolver-cu12      11.4.5.107               pypi_0    pypi
nvidia-cusparse-cu12      12.1.0.106               pypi_0    pypi
nvidia-ml-py              12.560.30                pypi_0    pypi
nvidia-nccl-cu12          2.20.5                   pypi_0    pypi
nvidia-nvjitlink-cu12     12.6.68                  pypi_0    pypi
nvidia-nvtx-cu12          12.1.105                 pypi_0    pypi
openai                    1.48.0                   pypi_0    pypi
openssl                   3.0.15               h5eee18b_0  
outlines                  0.0.46                   pypi_0    pypi
overrides                 7.7.0                    pypi_0    pypi
packaging                 24.1                     pypi_0    pypi
pandas                    2.2.3                    pypi_0    pypi
pandocfilters             1.5.1                    pypi_0    pypi
parso                     0.8.4                    pypi_0    pypi
partial-json-parser       0.2.1.1.post4            pypi_0    pypi
pexpect                   4.9.0                    pypi_0    pypi
pillow                    10.4.0                   pypi_0    pypi
pip                       24.2            py310h06a4308_0  
platformdirs              4.3.6                    pypi_0    pypi
prometheus-client         0.21.0                   pypi_0    pypi
prometheus-fastapi-instrumentator 7.0.0                    pypi_0    pypi
prompt-toolkit            3.0.48                   pypi_0    pypi
protobuf                  5.28.2                   pypi_0    pypi
psutil                    6.0.0                    pypi_0    pypi
ptyprocess                0.7.0                    pypi_0    pypi
pure-eval                 0.2.3                    pypi_0    pypi
py-cpuinfo                9.0.0                    pypi_0    pypi
pyairports                2.1.1                    pypi_0    pypi
pyarrow                   17.0.0                   pypi_0    pypi
pycountry                 24.6.1                   pypi_0    pypi
pycparser                 2.22                     pypi_0    pypi
pydantic                  2.9.2                    pypi_0    pypi
pydantic-core             2.23.4                   pypi_0    pypi
pygments                  2.18.0                   pypi_0    pypi
python                    3.10.14              h955ad1f_1  
python-dateutil           2.9.0.post0              pypi_0    pypi
python-dotenv             1.0.1                    pypi_0    pypi
python-json-logger        2.0.7                    pypi_0    pypi
pytz                      2024.2                   pypi_0    pypi
pyyaml                    6.0.2                    pypi_0    pypi
pyzmq                     26.2.0                   pypi_0    pypi
ray                       2.37.0                   pypi_0    pypi
readline                  8.2                  h5eee18b_0  
referencing               0.35.1                   pypi_0    pypi
regex                     2024.9.11                pypi_0    pypi
requests                  2.32.3                   pypi_0    pypi
rfc3339-validator         0.1.4                    pypi_0    pypi
rfc3986-validator         0.1.1                    pypi_0    pypi
rpds-py                   0.20.0                   pypi_0    pypi
safetensors               0.4.5                    pypi_0    pypi
send2trash                1.8.3                    pypi_0    pypi
sentencepiece             0.2.0                    pypi_0    pypi
setuptools                75.1.0          py310h06a4308_0  
six                       1.16.0                   pypi_0    pypi
sniffio                   1.3.1                    pypi_0    pypi
soupsieve                 2.6                      pypi_0    pypi
sqlite                    3.45.3               h5eee18b_0  
stack-data                0.6.3                    pypi_0    pypi
stanza                    1.9.2                    pypi_0    pypi
starlette                 0.38.6                   pypi_0    pypi
sympy                     1.13.3                   pypi_0    pypi
terminado                 0.18.1                   pypi_0    pypi
tiktoken                  0.7.0                    pypi_0    pypi
timm                      1.0.12                   pypi_0    pypi
tinycss2                  1.4.0                    pypi_0    pypi
tk                        8.6.14               h39e8969_0  
tokenizers                0.20.0                   pypi_0    pypi
tomli                     2.2.1                    pypi_0    pypi
torch                     2.4.0                    pypi_0    pypi
torchvision               0.19.0                   pypi_0    pypi
tornado                   6.4.2                    pypi_0    pypi
tqdm                      4.66.5                   pypi_0    pypi
traitlets                 5.14.3                   pypi_0    pypi
transformers              4.45.0                   pypi_0    pypi
triton                    3.0.0                    pypi_0    pypi
types-python-dateutil     2.9.0.20241003           pypi_0    pypi
typing-extensions         4.12.2                   pypi_0    pypi
tzdata                    2024.2                   pypi_0    pypi
uri-template              1.3.0                    pypi_0    pypi
urllib3                   2.2.3                    pypi_0    pypi
uvicorn                   0.30.6                   pypi_0    pypi
uvloop                    0.20.0                   pypi_0    pypi
vllm                      0.6.2                    pypi_0    pypi
watchfiles                0.24.0                   pypi_0    pypi
wcwidth                   0.2.13                   pypi_0    pypi
webcolors                 24.11.1                  pypi_0    pypi
webencodings              0.5.1                    pypi_0    pypi
websocket-client          1.8.0                    pypi_0    pypi
websockets                13.1                     pypi_0    pypi
wheel                     0.44.0          py310h06a4308_0  
widgetsnbextension        4.0.13                   pypi_0    pypi
xformers                  0.0.27.post2             pypi_0    pypi
xxhash                    3.5.0                    pypi_0    pypi
xz                        5.4.6                h5eee18b_1  
yarl                      1.12.1                   pypi_0    pypi
zipp                      3.20.2                   pypi_0    pypi
zlib                      1.2.13               h5eee18b_1  
Package                           Version
--------------------------------- --------------
accelerate                        1.1.1
aiohappyeyeballs                  2.4.0
aiohttp                           3.10.6
aiosignal                         1.3.1
annotated-types                   0.7.0
anthropic                         0.40.0
anyio                             4.6.0
argon2-cffi                       23.1.0
argon2-cffi-bindings              21.2.0
arrow                             1.3.0
asttokens                         3.0.0
async-lru                         2.0.4
async-timeout                     4.0.3
attrs                             24.2.0
babel                             2.16.0
beautifulsoup4                    4.12.3
bleach                            6.2.0
certifi                           2024.8.30
cffi                              1.17.1
charset-normalizer                3.3.2
click                             8.1.7
cloudpickle                       3.0.0
comm                              0.2.2
datasets                          3.0.1
debugpy                           1.8.9
decorator                         5.1.1
defusedxml                        0.7.1
dill                              0.3.8
diskcache                         5.6.3
distro                            1.9.0
einops                            0.8.0
emoji                             2.14.0
exceptiongroup                    1.2.2
executing                         2.1.0
fastapi                           0.115.0
fastjsonschema                    2.21.1
filelock                          3.16.1
fqdn                              1.5.1
frozenlist                        1.4.1
fsspec                            2024.6.1
gguf                              0.10.0
h11                               0.14.0
httpcore                          1.0.5
httptools                         0.6.1
httpx                             0.28.0
huggingface-hub                   0.25.1
idna                              3.10
importlib_metadata                8.5.0
interegular                       0.3.3
ipykernel                         6.29.5
ipython                           8.30.0
ipywidgets                        8.1.5
isoduration                       20.11.0
jedi                              0.19.2
Jinja2                            3.1.4
jiter                             0.5.0
json5                             0.10.0
jsonpointer                       3.0.0
jsonschema                        4.23.0
jsonschema-specifications         2023.12.1
jupyter                           1.1.1
jupyter_client                    8.6.3
jupyter-console                   6.6.3
jupyter_core                      5.7.2
jupyter-events                    0.10.0
jupyter-lsp                       2.2.5
jupyter_server                    2.14.2
jupyter_server_terminals          0.5.3
jupyterlab                        4.3.2
jupyterlab_pygments               0.3.0
jupyterlab_server                 2.27.3
jupyterlab_widgets                3.0.13
lark                              1.2.2
llvmlite                          0.43.0
lm-format-enforcer                0.10.6
MarkupSafe                        2.1.5
matplotlib-inline                 0.1.7
mistral_common                    1.4.3
mistune                           3.0.2
mpmath                            1.3.0
msgpack                           1.1.0
msgspec                           0.18.6
multidict                         6.1.0
multiprocess                      0.70.16
nbclient                          0.10.1
nbconvert                         7.16.4
nbformat                          5.10.4
nest-asyncio                      1.6.0
networkx                          3.3
notebook                          7.3.1
notebook_shim                     0.2.4
numba                             0.60.0
numpy                             1.26.4
nvidia-cublas-cu12                12.1.3.1
nvidia-cuda-cupti-cu12            12.1.105
nvidia-cuda-nvrtc-cu12            12.1.105
nvidia-cuda-runtime-cu12          12.1.105
nvidia-cudnn-cu12                 9.1.0.70
nvidia-cufft-cu12                 11.0.2.54
nvidia-curand-cu12                10.3.2.106
nvidia-cusolver-cu12              11.4.5.107
nvidia-cusparse-cu12              12.1.0.106
nvidia-ml-py                      12.560.30
nvidia-nccl-cu12                  2.20.5
nvidia-nvjitlink-cu12             12.6.68
nvidia-nvtx-cu12                  12.1.105
openai                            1.48.0
outlines                          0.0.46
overrides                         7.7.0
packaging                         24.1
pandas                            2.2.3
pandocfilters                     1.5.1
parso                             0.8.4
partial-json-parser               0.2.1.1.post4
pexpect                           4.9.0
pillow                            10.4.0
pip                               24.2
platformdirs                      4.3.6
prometheus_client                 0.21.0
prometheus-fastapi-instrumentator 7.0.0
prompt_toolkit                    3.0.48
protobuf                          5.28.2
psutil                            6.0.0
ptyprocess                        0.7.0
pure_eval                         0.2.3
py-cpuinfo                        9.0.0
pyairports                        2.1.1
pyarrow                           17.0.0
pycountry                         24.6.1
pycparser                         2.22
pydantic                          2.9.2
pydantic_core                     2.23.4
Pygments                          2.18.0
python-dateutil                   2.9.0.post0
python-dotenv                     1.0.1
python-json-logger                2.0.7
pytz                              2024.2
PyYAML                            6.0.2
pyzmq                             26.2.0
ray                               2.37.0
referencing                       0.35.1
regex                             2024.9.11
requests                          2.32.3
rfc3339-validator                 0.1.4
rfc3986-validator                 0.1.1
rpds-py                           0.20.0
safetensors                       0.4.5
Send2Trash                        1.8.3
sentencepiece                     0.2.0
setuptools                        75.1.0
six                               1.16.0
sniffio                           1.3.1
soupsieve                         2.6
stack-data                        0.6.3
stanza                            1.9.2
starlette                         0.38.6
sympy                             1.13.3
terminado                         0.18.1
tiktoken                          0.7.0
timm                              1.0.12
tinycss2                          1.4.0
tokenizers                        0.20.0
tomli                             2.2.1
torch                             2.4.0
torchvision                       0.19.0
tornado                           6.4.2
tqdm                              4.66.5
traitlets                         5.14.3
transformers                      4.45.0
triton                            3.0.0
types-python-dateutil             2.9.0.20241003
typing_extensions                 4.12.2
tzdata                            2024.2
uri-template                      1.3.0
urllib3                           2.2.3
uvicorn                           0.30.6
uvloop                            0.20.0
vllm                              0.6.2
watchfiles                        0.24.0
wcwidth                           0.2.13
webcolors                         24.11.1
webencodings                      0.5.1
websocket-client                  1.8.0
websockets                        13.1
wheel                             0.44.0
widgetsnbextension                4.0.13
xformers                          0.0.27.post2
xxhash                            3.5.0
yarl                              1.12.1
zipp                              3.20.2

Currently Loaded Modules:
  1) eth_proxy      4) stack/2024-06   7) python/3.11.6  10) openblas/0.3.24
  2) julia/1.10.3   5) r/4.3.2         8) cuda/12.1.1    11) python_cuda/3.11.6
  3) gcc/12.2.0     6) hdf5/1.14.3     9) nccl/2.18.3-1

 

Testing Slurm Variables...
SLURM_JOB_USER=gcardenal
SLURM_TASKS_PER_NODE=1
SLURM_JOB_UID=608619
SLURM_TASK_PID=2088290
SLURM_JOB_GPUS=5,9
SLURM_LOCALID=0
SLURM_SUBMIT_DIR=/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation
SLURMD_NODENAME=eu-a65-05
SLURM_JOB_START_TIME=1734081006
SLURM_CLUSTER_NAME=euler-24-production
SLURM_JOB_END_TIME=1734095406
SLURM_CPUS_ON_NODE=8
SLURM_JOB_CPUS_PER_NODE=8
SLURM_GPUS_ON_NODE=2
SLURM_GTIDS=0
SLURM_JOB_PARTITION=gpupr.4h
SLURM_TRES_PER_TASK=cpu=8
SLURM_JOB_NUM_NODES=1
SLURM_JOBID=18217740
SLURM_GPUS=nvidia_a100_80gb_pcie:2
SLURM_JOB_QOS=es_ilic/gpupr/4
SLURM_PROCID=0
SLURM_CPUS_PER_TASK=8
SLURM_NTASKS=1
SLURM_TOPOLOGY_ADDR=.euler_a100_80_lca_ib.eu-a65-05
SLURM_TOPOLOGY_ADDR_PATTERN=switch.switch.node
SLURM_MEM_PER_CPU=10240
SLURM_SCRIPT_CONTEXT=prolog_task
SLURM_NODELIST=eu-a65-05
SLURM_JOB_ACCOUNT=gpupr/es_ilic
SLURM_PRIO_PROCESS=0
SLURM_NPROCS=1
SLURM_NNODES=1
SLURM_SUBMIT_HOST=eu-lo-g3-004
SLURM_JOB_ID=18217740
SLURM_NODEID=0
SLURM_CONF=/cluster/slurm/adm/etc/slurm.conf
SLURM_JOB_NAME=llama_no_api
SLURM_JOB_GID=492010
SLURM_JOB_NODELIST=eu-a65-05
Fri Dec 13 10:10:18 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:88:00.0 Off |                    0 |
| N/A   32C    P0             44W /  300W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:CD:00.0 Off |                    0 |
| N/A   33C    P0             43W /  300W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Node IP: 10.205.9.14
JobId=18217740 JobName=llama_no_api
   UserId=gcardenal(608619) GroupId=gcardenal-group(492010) MCS_label=N/A
   Priority=5783 Nice=0 Account=gpupr/es_ilic QOS=es_ilic/gpupr/4
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:00:13 TimeLimit=04:00:00 TimeMin=N/A
   SubmitTime=2024-12-13T10:09:08 EligibleTime=2024-12-13T10:09:08
   AccrueTime=2024-12-13T10:09:08
   StartTime=2024-12-13T10:10:06 EndTime=2024-12-13T14:10:06 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2024-12-13T10:10:06 Scheduler=Backfill
   Partition=gpupr.4h AllocNode:Sid=eu-lo-g3-004:2029661
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=eu-a65-05
   BatchHost=eu-a65-05
   NumNodes=1 NumCPUs=8 NumTasks=1 CPUs/Task=8 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=8,mem=80G,node=1,billing=347340,gres/gpu=2,gres/gpu:nvidia_a100_80gb_pcie=2,gres/gpumem=85899345920
   AllocTRES=cpu=8,mem=80G,node=1,billing=347340,gres/gpu=2,gres/gpu:nvidia_a100_80gb_pcie=2,gres/gpumem=0
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:1 CoreSpec=*
   MinCPUsNode=8 MinMemoryCPU=10G MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation/generate_answers.sh
   WorkDir=/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation
   StdErr=/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation/llama_no_api18217740.out
   StdIn=/dev/null
   StdOut=/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation/llama_no_api18217740.out
   TresPerJob=gres/gpu:nvidia_a100_80gb_pcie:2
   TresPerNode=gres/gpumem:80G
   TresPerTask=cpu=8
   

Running in standalone mode...
I1213 10:10:22.209000 22392829429568 torch/distributed/run.py:859] 
I1213 10:10:22.209000 22392829429568 torch/distributed/run.py:859] **************************************
I1213 10:10:22.209000 22392829429568 torch/distributed/run.py:859] Rendezvous info:
I1213 10:10:22.209000 22392829429568 torch/distributed/run.py:859] --rdzv-backend=c10d --rdzv-endpoint=localhost:0 --rdzv-id=223e52ab-9af8-40f8-98b5-679402aac0b2
I1213 10:10:22.209000 22392829429568 torch/distributed/run.py:859] **************************************
I1213 10:10:22.209000 22392829429568 torch/distributed/run.py:859] 
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188] Starting elastic_operator with launch configs:
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   entrypoint       : get_model_answers_and_prompt_generation.py
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   min_nodes        : 1
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   max_nodes        : 1
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   nproc_per_node   : 1
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   run_id           : 223e52ab-9af8-40f8-98b5-679402aac0b2
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   rdzv_backend     : c10d
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   rdzv_endpoint    : localhost:0
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   rdzv_configs     : {'timeout': 900}
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   max_restarts     : 0
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   monitor_interval : 5
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   log_dir          : /scratch/tmp.18217740.gcardenal/torchelastic_rqapu3aj
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188]   metrics_cfg      : {}
I1213 10:10:22.210000 22392829429568 torch/distributed/launcher/api.py:188] 
I1213 10:10:22.220000 22392829429568 torch/distributed/elastic/agent/server/api.py:866] [default] starting workers for entrypoint: python3
I1213 10:10:22.220000 22392829429568 torch/distributed/elastic/agent/server/api.py:699] [default] Rendezvous'ing worker group
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568] [default] Rendezvous complete for workers. Result:
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   restart_count=0
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   master_addr=eu-a65-05.euler.ethz.ch
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   master_port=50849
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   group_rank=0
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   group_world_size=1
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   local_ranks=[0]
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   role_ranks=[0]
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   global_ranks=[0]
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   role_world_sizes=[1]
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568]   global_world_sizes=[1]
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:568] 
I1213 10:10:22.437000 22392829429568 torch/distributed/elastic/agent/server/api.py:707] [default] Starting worker group
I1213 10:10:22.438000 22392829429568 torch/distributed/elastic/agent/server/local_elastic_agent.py:168] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
I1213 10:10:22.438000 22392829429568 torch/distributed/elastic/multiprocessing/api.py:263] log directory set to: /scratch/tmp.18217740.gcardenal/torchelastic_rqapu3aj/223e52ab-9af8-40f8-98b5-679402aac0b2_0la_0nk6
I1213 10:10:22.438000 22392829429568 torch/distributed/elastic/multiprocessing/api.py:358] Setting worker0 reply file to: /scratch/tmp.18217740.gcardenal/torchelastic_rqapu3aj/223e52ab-9af8-40f8-98b5-679402aac0b2_0la_0nk6/attempt_0/0/error.json
Loading Med42 model...
2024-12-13 10:10:32.397785: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-12-13 10:10:32.397830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-12-13 10:10:32.399139: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-13 10:10:32.404125: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-13 10:10:34.213602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading shards:   0%|                                                                    | 0/30 [00:00<?, ?it/s]Downloading shards:   3%|█▉                                                         | 1/30 [01:49<52:54, 109.46s/it]Downloading shards:   7%|███▉                                                       | 2/30 [03:41<51:39, 110.69s/it]Downloading shards:  10%|█████▋                                                   | 3/30 [07:12<1:10:35, 156.89s/it]Downloading shards:  13%|███████▌                                                 | 4/30 [09:11<1:01:23, 141.67s/it]Downloading shards:  17%|█████████▊                                                 | 5/30 [11:01<54:21, 130.46s/it]Downloading shards:  20%|███████████▊                                               | 6/30 [12:52<49:32, 123.85s/it]Downloading shards:  23%|█████████████▊                                             | 7/30 [14:44<45:59, 119.97s/it]Downloading shards:  27%|███████████████▋                                           | 8/30 [16:56<45:21, 123.71s/it]Downloading shards:  30%|█████████████████▋                                         | 9/30 [18:55<42:47, 122.27s/it]Downloading shards:  33%|███████████████████▎                                      | 10/30 [20:46<39:36, 118.85s/it]Downloading shards:  37%|█████████████████████▎                                    | 11/30 [22:42<37:19, 117.88s/it]Downloading shards:  40%|███████████████████████▏                                  | 12/30 [24:33<34:45, 115.88s/it]Downloading shards:  43%|█████████████████████████▏                                | 13/30 [26:33<33:11, 117.17s/it]Downloading shards:  47%|███████████████████████████                               | 14/30 [28:32<31:19, 117.44s/it]Downloading shards:  50%|█████████████████████████████                             | 15/30 [30:22<28:51, 115.44s/it]Downloading shards:  53%|██████████████████████████████▉                           | 16/30 [32:13<26:37, 114.11s/it]Downloading shards:  57%|████████████████████████████████▊                         | 17/30 [34:05<24:35, 113.51s/it]Downloading shards:  60%|██████████████████████████████████▊                       | 18/30 [36:55<26:03, 130.31s/it]Downloading shards:  63%|████████████████████████████████████▋                     | 19/30 [38:55<23:20, 127.32s/it]Downloading shards:  67%|██████████████████████████████████████▋                   | 20/30 [41:20<22:05, 132.53s/it]Downloading shards:  70%|████████████████████████████████████████▌                 | 21/30 [43:12<18:58, 126.51s/it]Downloading shards:  73%|██████████████████████████████████████████▌               | 22/30 [45:04<16:17, 122.20s/it]Downloading shards:  77%|████████████████████████████████████████████▍             | 23/30 [47:42<15:30, 132.89s/it]Downloading shards:  80%|██████████████████████████████████████████████▍           | 24/30 [49:42<12:53, 128.93s/it]Downloading shards:  83%|████████████████████████████████████████████████▎         | 25/30 [51:35<10:21, 124.28s/it]Downloading shards:  87%|██████████████████████████████████████████████████▎       | 26/30 [53:26<08:01, 120.28s/it]Downloading shards:  90%|████████████████████████████████████████████████████▏     | 27/30 [55:17<05:52, 117.47s/it]Downloading shards:  93%|██████████████████████████████████████████████████████▏   | 28/30 [57:54<04:18, 129.18s/it]Downloading shards:  97%|████████████████████████████████████████████████████████  | 29/30 [59:57<02:07, 127.25s/it]Downloading shards: 100%|████████████████████████████████████████████████████████| 30/30 [1:00:46<00:00, 103.97s/it]Downloading shards: 100%|████████████████████████████████████████████████████████| 30/30 [1:00:46<00:00, 121.56s/it]
Loading checkpoint shards:   0%|                                                             | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|█▊                                                   | 1/30 [00:05<02:40,  5.53s/it]Loading checkpoint shards:   7%|███▌                                                 | 2/30 [00:11<02:34,  5.51s/it]Loading checkpoint shards:  10%|█████▎                                               | 3/30 [00:21<03:27,  7.67s/it]Loading checkpoint shards:  13%|███████                                              | 4/30 [00:27<03:01,  6.97s/it]Loading checkpoint shards:  17%|████████▊                                            | 5/30 [00:33<02:51,  6.84s/it]Loading checkpoint shards:  20%|██████████▌                                          | 6/30 [00:39<02:34,  6.46s/it]Loading checkpoint shards:  23%|████████████▎                                        | 7/30 [00:45<02:23,  6.22s/it]Loading checkpoint shards:  27%|██████████████▏                                      | 8/30 [00:51<02:19,  6.33s/it]Loading checkpoint shards:  30%|███████████████▉                                     | 9/30 [01:14<03:58, 11.36s/it]Loading checkpoint shards:  33%|█████████████████▎                                  | 10/30 [01:20<03:14,  9.72s/it]Loading checkpoint shards:  37%|███████████████████                                 | 11/30 [01:38<03:53, 12.30s/it]Loading checkpoint shards:  40%|████████████████████▊                               | 12/30 [01:44<03:09, 10.53s/it]Loading checkpoint shards:  43%|██████████████████████▌                             | 13/30 [02:06<03:53, 13.75s/it]Loading checkpoint shards:  47%|████████████████████████▎                           | 14/30 [02:12<03:02, 11.43s/it]Loading checkpoint shards:  50%|██████████████████████████                          | 15/30 [02:17<02:24,  9.66s/it]Loading checkpoint shards:  53%|███████████████████████████▋                        | 16/30 [02:23<02:00,  8.59s/it]Loading checkpoint shards:  57%|█████████████████████████████▍                      | 17/30 [02:29<01:41,  7.79s/it]Loading checkpoint shards:  60%|███████████████████████████████▏                    | 18/30 [02:36<01:29,  7.45s/it]Loading checkpoint shards:  63%|████████████████████████████████▉                   | 19/30 [02:56<02:03, 11.27s/it]Loading checkpoint shards:  67%|██████████████████████████████████▋                 | 20/30 [03:07<01:50, 11.04s/it]Loading checkpoint shards:  70%|████████████████████████████████████▍               | 21/30 [03:13<01:25,  9.52s/it]Loading checkpoint shards:  73%|██████████████████████████████████████▏             | 22/30 [03:40<01:59, 14.91s/it]Loading checkpoint shards:  77%|███████████████████████████████████████▊            | 23/30 [03:50<01:34, 13.45s/it]Loading checkpoint shards:  80%|█████████████████████████████████████████▌          | 24/30 [04:14<01:38, 16.45s/it]Loading checkpoint shards:  83%|███████████████████████████████████████████▎        | 25/30 [04:26<01:16, 15.24s/it]Loading checkpoint shards:  87%|█████████████████████████████████████████████       | 26/30 [04:31<00:49, 12.33s/it]Loading checkpoint shards:  90%|██████████████████████████████████████████████▊     | 27/30 [04:45<00:37, 12.64s/it]Loading checkpoint shards:  93%|████████████████████████████████████████████████▌   | 28/30 [05:04<00:29, 14.71s/it]Loading checkpoint shards:  97%|██████████████████████████████████████████████████▎ | 29/30 [05:11<00:12, 12.38s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 30/30 [05:15<00:00,  9.67s/it]Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 30/30 [05:15<00:00, 10.50s/it]
Starting inference for question (Med42): How is HIV diagnosed?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What are the different stages of HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How is HIV transmitted?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What comorbidities are common among people living 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How can HIV be prevented?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How frequently ART must be taken?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How can we prevent Perinatal transmission of HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What are the main cell types infected with HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What is the difference between HIV and AIDS?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How is HIV not transmitted?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_1.1_HIV_EQ.json done
Starting inference for question (Med42): How is HIV diagnosed?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What are the different stages of HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How is HIV transmitted?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What comorbidities are common among people living 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How can HIV be prevented?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How frequently ART must be taken?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How can we prevent Perinatal transmission of HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What are the main cell types infected with HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What is the difference between HIV and AIDS?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How is HIV not transmitted?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_1.2_HIV_EQ.json done
Starting inference for question (Med42): How is HIV diagnosed?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What are the different stages of HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How is HIV transmitted?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What comorbidities are common among people living 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How can HIV be prevented?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How frequently ART must be taken?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How can we prevent Perinatal transmission of HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What are the main cell types infected with HIV?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What is the difference between HIV and AIDS?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): How is HIV not transmitted?
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_1.3_HIV_EQ.json done
Starting inference for question (Med42): Which five antiretroviral drugs were most frequent
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Which five antiretroviral drugs  were most frequen
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Is there a difference in the overall birth rate in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Is there a difference in the overall birth rate in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What is the most common source of HIV infection in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): In Switzerland, based on self-reported treatment a
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): From 2020, what is the proportion of PLWH who 'fee
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): From 2020, what proportion of PWH consider that 'P
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What proportion of PWH who died from HIV-related c
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): For individuals who had their first positive HIV t
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_2.1_HIV_EQ.json done
Starting inference for question (Med42): Which five antiretroviral drugs were most frequent
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Which five antiretroviral drugs  were most frequen
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Is there a difference in the overall birth rate in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Is there a difference in the overall birth rate in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What is the most common source of HIV infection in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): In Switzerland, based on self-reported treatment a
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): From 2020, what is the proportion of PLWH who 'fee
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): From 2020, what proportion of PWH consider that 'P
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What proportion of PWH who died from HIV-related c
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): For individuals who had their first positive HIV t
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_2.2_HIV_EQ.json done
Starting inference for question (Med42): Which five antiretroviral drugs were most frequent
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Which five antiretroviral drugs  were most frequen
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Is there a difference in the overall birth rate in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Is there a difference in the overall birth rate in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What is the most common source of HIV infection in
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): In Switzerland, based on self-reported treatment a
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): From 2020, what is the proportion of PLWH who 'fee
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): From 2020, what proportion of PWH consider that 'P
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): What proportion of PWH who died from HIV-related c
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): For individuals who had their first positive HIV t
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_2.3_HIV_EQ.json done
Starting inference for question (Med42): A 58-year-old woman with HIV infection is brought 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old sexually active male presents to an 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A mother with HIV has given birth to a healthy boy
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old woman presents to a physician’s offi
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A physician scientist is looking for a more effici
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 50-year-old HIV-positive male presents to the ER
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 43-year-old man with HIV infection comes to the 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 28-year-old G1P0 woman at 16 weeks estimated ges
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 32-year-old man comes to the office for a routin
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 41-year-old HIV-positive male presents to the ER
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_3.1_HIV_EQ.json done
Starting inference for question (Med42): A 58-year-old woman with HIV infection is brought 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old sexually active male presents to an 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A mother with HIV has given birth to a healthy boy
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old woman presents to a physician’s offi
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A physician scientist is looking for a more effici
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 50-year-old HIV-positive male presents to the ER
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 43-year-old man with HIV infection comes to the 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 28-year-old G1P0 woman at 16 weeks estimated ges
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 32-year-old man comes to the office for a routin
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 41-year-old HIV-positive male presents to the ER
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_3.2_HIV_EQ.json done
Starting inference for question (Med42): A 58-year-old woman with HIV infection is brought 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old sexually active male presents to an 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A mother with HIV has given birth to a healthy boy
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old woman presents to a physician’s offi
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A physician scientist is looking for a more effici
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 50-year-old HIV-positive male presents to the ER
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 43-year-old man with HIV infection comes to the 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 28-year-old G1P0 woman at 16 weeks estimated ges
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 32-year-old man comes to the office for a routin
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 41-year-old HIV-positive male presents to the ER
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_3.3_HIV_EQ.json done
Starting inference for question (Med42): A 26-year-old female with AIDS (CD4 count: 47) pre
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): You are reviewing raw data from a research study p
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 46-year-old Caucasian male with past medical his
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 44-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old nulliparous woman at 8 weeks' gestat
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 33-year-old HIV-positive male is seen in clinic 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 30-year-old woman with HIV comes to the emergenc
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old man comes to the physician because o
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 52-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 2300-g (5-lb 1-oz) male newborn is delivered to 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_4.1_HIV_EQ.json done
Starting inference for question (Med42): A 26-year-old female with AIDS (CD4 count: 47) pre
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): You are reviewing raw data from a research study p
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 46-year-old Caucasian male with past medical his
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 44-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old nulliparous woman at 8 weeks' gestat
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 33-year-old HIV-positive male is seen in clinic 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 30-year-old woman with HIV comes to the emergenc
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old man comes to the physician because o
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 52-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 2300-g (5-lb 1-oz) male newborn is delivered to 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_4.2_HIV_EQ.json done
Starting inference for question (Med42): A 26-year-old female with AIDS (CD4 count: 47) pre
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): You are reviewing raw data from a research study p
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 46-year-old Caucasian male with past medical his
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 44-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old nulliparous woman at 8 weeks' gestat
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 33-year-old HIV-positive male is seen in clinic 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 30-year-old woman with HIV comes to the emergenc
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old man comes to the physician because o
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 52-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 2300-g (5-lb 1-oz) male newborn is delivered to 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_4.3_HIV_EQ.json done
Starting inference for question (Med42): A 54-year-old woman and a 54-year-old man with CVD
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): It is late at night in the clinic and I still have
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): I have two HIV-positive patients under ART. One is
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Do black people have higher HIV infection rates be
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): In Uganda, homosexuality is considered a felony th
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): 32-year-old male patient, MSM, no significant past
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 34-year-old HIV-positive pregnant woman presents
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 45-year-old woman comes to the clinic after test
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 27-year-old male who was diagnosed HIV positive 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 50-year-old female patient who recently started 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 32-year-old male patient on a strict PrEP regime
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_5.1_HIV_EQ.json done
Starting inference for question (Med42): A 54-year-old woman and a 54-year-old man with CVD
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): It is late at night in the clinic and I still have
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): I have two HIV-positive patients under ART. One is
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Do black people have higher HIV infection rates be
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): In Uganda, homosexuality is considered a felony th
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): 32-year-old male patient, MSM, no significant past
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 34-year-old HIV-positive pregnant woman presents
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 45-year-old woman comes to the clinic after test
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 27-year-old male who was diagnosed HIV positive 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 50-year-old female patient who recently started 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 32-year-old male patient on a strict PrEP regime
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_5.2_HIV_EQ.json done
Starting inference for question (Med42): A 54-year-old woman and a 54-year-old man with CVD
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): It is late at night in the clinic and I still have
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): I have two HIV-positive patients under ART. One is
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): Do black people have higher HIV infection rates be
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): In Uganda, homosexuality is considered a felony th
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): 32-year-old male patient, MSM, no significant past
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 34-year-old HIV-positive pregnant woman presents
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 45-year-old woman comes to the clinic after test
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 27-year-old male who was diagnosed HIV positive 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 50-year-old female patient who recently started 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 32-year-old male patient on a strict PrEP regime
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_5.3_HIV_EQ.json done
Starting inference for question (Med42): A 26-year-old female with AIDS (CD4 count: 47) pre
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): You are reviewing raw data from a research study p
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 46-year-old Caucasian male with past medical his
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 44-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old nulliparous woman at 8 weeks' gestat
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 33-year-old HIV-positive male is seen in clinic 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 30-year-old woman with HIV comes to the emergenc
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old man comes to the physician because o
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 52-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 2300-g (5-lb 1-oz) male newborn is delivered to 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_6.1_HIV_EQ.json done
Starting inference for question (Med42): A 26-year-old female with AIDS (CD4 count: 47) pre
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): You are reviewing raw data from a research study p
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 46-year-old Caucasian male with past medical his
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 44-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old nulliparous woman at 8 weeks' gestat
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 33-year-old HIV-positive male is seen in clinic 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 30-year-old woman with HIV comes to the emergenc
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old man comes to the physician because o
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 52-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 2300-g (5-lb 1-oz) male newborn is delivered to 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_6.2_HIV_EQ.json done
Starting inference for question (Med42): A 26-year-old female with AIDS (CD4 count: 47) pre
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): You are reviewing raw data from a research study p
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 46-year-old Caucasian male with past medical his
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 44-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 25-year-old nulliparous woman at 8 weeks' gestat
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 33-year-old HIV-positive male is seen in clinic 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 30-year-old woman with HIV comes to the emergenc
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 35-year-old man comes to the physician because o
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 52-year-old man is brought to the emergency depa
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Starting inference for question (Med42): A 2300-g (5-lb 1-oz) male newborn is delivered to 
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Med42_answers_category_6.3_HIV_EQ.json done
Loading NVLM model...
/cluster/home/gcardenal/.local/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/cluster/home/gcardenal/.local/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/cluster/home/gcardenal/.local/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/cluster/home/gcardenal/.local/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/cluster/home/gcardenal/.local/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Loading checkpoint shards:   0%|                                                             | 0/46 [00:00<?, ?it/s]Loading checkpoint shards:   2%|█▏                                                   | 1/46 [00:04<03:13,  4.30s/it]Loading checkpoint shards:   4%|██▎                                                  | 2/46 [00:31<13:10, 17.96s/it]Loading checkpoint shards:   7%|███▍                                                 | 3/46 [01:00<16:27, 22.96s/it]Loading checkpoint shards:   9%|████▌                                                | 4/46 [01:37<20:01, 28.60s/it]Loading checkpoint shards:  11%|█████▊                                               | 5/46 [02:04<19:02, 27.88s/it]Loading checkpoint shards:  13%|██████▉                                              | 6/46 [02:41<20:32, 30.80s/it]Loading checkpoint shards:  15%|████████                                             | 7/46 [03:30<23:55, 36.80s/it]Loading checkpoint shards:  17%|█████████▏                                           | 8/46 [03:59<21:45, 34.35s/it]Loading checkpoint shards:  20%|██████████▎                                          | 9/46 [04:26<19:46, 32.08s/it]Loading checkpoint shards:  22%|███████████▎                                        | 10/46 [04:41<16:09, 26.92s/it]Loading checkpoint shards:  24%|████████████▍                                       | 11/46 [05:08<15:44, 26.99s/it]Loading checkpoint shards:  26%|█████████████▌                                      | 12/46 [05:32<14:41, 25.93s/it]Loading checkpoint shards:  28%|██████████████▋                                     | 13/46 [05:57<14:11, 25.81s/it]Loading checkpoint shards:  30%|███████████████▊                                    | 14/46 [06:40<16:31, 30.99s/it]Loading checkpoint shards:  33%|████████████████▉                                   | 15/46 [07:08<15:30, 30.03s/it]Loading checkpoint shards:  35%|██████████████████                                  | 16/46 [07:37<14:46, 29.56s/it]Loading checkpoint shards:  37%|███████████████████▏                                | 17/46 [08:06<14:14, 29.47s/it]Loading checkpoint shards:  39%|████████████████████▎                               | 18/46 [08:33<13:22, 28.66s/it]Loading checkpoint shards:  41%|█████████████████████▍                              | 19/46 [08:59<12:30, 27.81s/it]Loading checkpoint shards:  43%|██████████████████████▌                             | 20/46 [09:27<12:05, 27.92s/it]Loading checkpoint shards:  46%|███████████████████████▋                            | 21/46 [10:54<19:05, 45.82s/it]Loading checkpoint shards:  48%|████████████████████████▊                           | 22/46 [11:39<18:14, 45.60s/it]Loading checkpoint shards:  50%|██████████████████████████                          | 23/46 [12:08<15:29, 40.40s/it]Loading checkpoint shards:  52%|███████████████████████████▏                        | 24/46 [12:22<11:54, 32.50s/it]Loading checkpoint shards:  54%|████████████████████████████▎                       | 25/46 [12:41<10:00, 28.61s/it]Loading checkpoint shards:  57%|█████████████████████████████▍                      | 26/46 [13:00<08:30, 25.52s/it]Loading checkpoint shards:  59%|██████████████████████████████▌                     | 27/46 [13:17<07:19, 23.13s/it]Loading checkpoint shards:  61%|███████████████████████████████▋                    | 28/46 [13:46<07:26, 24.82s/it]Loading checkpoint shards:  63%|████████████████████████████████▊                   | 29/46 [14:11<07:05, 25.01s/it]Loading checkpoint shards:  65%|█████████████████████████████████▉                  | 30/46 [14:39<06:52, 25.80s/it]Loading checkpoint shards:  67%|███████████████████████████████████                 | 31/46 [15:12<06:59, 27.96s/it]Loading checkpoint shards:  70%|████████████████████████████████████▏               | 32/46 [15:25<05:29, 23.50s/it]Loading checkpoint shards:  72%|█████████████████████████████████████▎              | 33/46 [15:53<05:23, 24.88s/it]Loading checkpoint shards:  74%|██████████████████████████████████████▍             | 34/46 [16:24<05:18, 26.54s/it]Loading checkpoint shards:  76%|███████████████████████████████████████▌            | 35/46 [17:22<06:37, 36.12s/it]Loading checkpoint shards:  78%|████████████████████████████████████████▋           | 36/46 [18:24<07:18, 43.89s/it]Loading checkpoint shards:  80%|█████████████████████████████████████████▊          | 37/46 [19:01<06:17, 41.90s/it]Loading checkpoint shards:  83%|██████████████████████████████████████████▉         | 38/46 [19:34<05:12, 39.01s/it]Loading checkpoint shards:  83%|██████████████████████████████████████████▉         | 38/46 [19:44<04:09, 31.17s/it]
Traceback (most recent call last):
  File "/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation/get_model_answers_and_prompt_generation.py", line 359, in <module>
    output_model_dir = obtain_answers_HIV(questions_dir=questions_dir, model_list=model_list)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation/get_model_answers_and_prompt_generation.py", line 237, in obtain_answers_HIV
    model_answer = run_nvlm_inference(question_text)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation/get_model_answers_and_prompt_generation.py", line 172, in run_nvlm_inference
    load_nvlm_model()
  File "/cluster/home/gcardenal/HIV/deploy_medical_LLM_evaluation/deploy_medical_llm_evaluation/get_model_answers_and_prompt_generation.py", line 160, in load_nvlm_model
    model = AutoModelForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/gcardenal/.local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 559, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/gcardenal/.local/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/gcardenal/.local/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/gcardenal/.local/lib/python3.11/site-packages/transformers/modeling_utils.py", line 993, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/cluster/home/gcardenal/.local/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 329, in set_module_tensor_to_device
    new_value = value.to(device)
                ^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 462.00 MiB. GPU  has a total capacity of 79.14 GiB of which 146.75 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 78.48 GiB is allocated by PyTorch, and 13.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
E1213 14:01:43.937000 22392829429568 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 2088366) of binary: /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/bin/python3
I1213 14:01:43.971000 22392829429568 torch/distributed/elastic/multiprocessing/errors/__init__.py:360] ('local_rank %s FAILED with no error file. Decorate your entrypoint fn with @record for traceback info. See: https://pytorch.org/docs/stable/elastic/errors.html', 0)
Traceback (most recent call last):
  File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/bin/torchrun", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/distributed/run.py", line 879, in main
    run(args)
  File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
get_model_answers_and_prompt_generation.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-13_14:01:43
  host      : eu-a65-05.euler.ethz.ch
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2088366)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: eu-a65-05: task 0: Exited with exit code 1
